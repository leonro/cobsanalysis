Sat May 30 03:30:01 UTC 2020
1. Identify primary instrument
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary MARCOS...
('Checking ', 'LEMI036_1_0002_0002')
(86400, '2020-05-30 03:25:13.000000', '2020-05-29 03:25:14.000000')
(datetime.datetime(2020, 5, 30, 3, 25, 13), datetime.datetime(2020, 5, 29, 3, 25, 14))
Coverage OK - using LEMI036_1_0002_0002
('Checking ', 'GP20S3NSS2_012201_0001_0001')
(86400, datetime.datetime(2020, 5, 30, 3, 25, 35, 120842))
Test 1 OK: data  available and last value not null
(datetime.datetime(2020, 5, 30, 3, 25, 35, 120842), datetime.datetime(2020, 5, 29, 3, 25, 28, 150150))
Test 2 OK: correct amount of data covering the last day
Get primary -> Using Variometer LEMI036_1_0002_0002 and Scalar GP20S3NSS2_012201_0001_0001
Dumping instruments as usual in the old way...
... done
('Got', {u'magnetism': {u'QD enddate': [u'2020-05-21', u''], u'k-time': [u'2020-05-30 01:30', u''], u'k': [2, u''], u'primary scalar': [u'GP20S3NSS2_012201_0001_0001', u''], u'k-warning': [0, u''], u'k-valid': [u'', u''], u'primary vario': [u'LEMI036_1_0002_0002', u''], u'QD analysis date': [u'2020-05-30', u'']}, u'logging': {u'failedupload2homepage': 1, u'magnetismplots': [u'2020-05-30 03:22', u''], u'seismoNEICdata': [u'2020-05-28 23:41', u''], u'seismoATdata': [u'2020-05-30 03:21', u'']}})
Logfile /var/log/magpy/mm-dp-getprimary.log loaded
Existing: SAGITTARIUS-DataProducts-getprimary-vario
Existing: SAGITTARIUS-DataProducts-getprimary-process
Existing: SAGITTARIUS-DataProducts-getprimary-scalar
Existing: SAGITTARIUS-DataProducts-getprimary-write
Sat May 30 03:30:05 UTC 2020
2. Automatic flags
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary MARCOS...
...success
 -------------------------------------------
 Dealing with sensorgroup which starts with GSM90_6
 -------------------------------------------
Using the following parameter: keys=['f'],threshold=5,window=0:05:00,limits=[None, None]
   -> Found ['GSM90_6107631_0001_0001', 'GSM90_6107632_0001_0001']
 a) select 1 second or highest resolution data
Sensor: GSM90_6107631_0001_0001 -> Samplingrate: 3.0
Sensor: GSM90_6107632_0001_0001 -> Samplingrate: 3.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_6107631_0001_0001
   Valid data for GSM90_6107632_0001_0001
 d) Flagging data
   - got 2400 datapoints
   - getting existing flags for GSM90_6107631_0001
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
   - got 2400 datapoints
   - getting existing flags for GSM90_6107632_0001
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with GP20S3NSS2
 -------------------------------------------
Using the following parameter: keys=['f'],threshold=5,window=None,limits=[None, None]
   -> Found ['GP20S3NSS2_012201_0001_0001']
 a) select 1 second or highest resolution data
Sensor: GP20S3NSS2_012201_0001_0001 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GP20S3NSS2_012201_0001_0001
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for GP20S3NSS2_012201_0001
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with GSM90_14245
 -------------------------------------------
Using the following parameter: keys=['f'],threshold=5,window=None,limits=[None, None]
   -> Found ['GSM90_14245_0002_0001', 'GSM90_14245_0002_0002', 'GSM90_14245_0002_0003']
 a) select 1 second or highest resolution data
Sensor: GSM90_14245_0002_0001 -> Samplingrate: 0.2
Sensor: GSM90_14245_0002_0002 -> Samplingrate: 1.0
Sensor: GSM90_14245_0002_0003 -> Samplingrate: 0.5
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_14245_0002_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for GSM90_14245_0002
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with FGE
 -------------------------------------------
Using the following parameter: keys=['x', 'y', 'z'],threshold=5,window=None,limits=[None, None]
   -> Found ['FGE_S0252_0001_0001']
 a) select 1 second or highest resolution data
Sensor: FGE_S0252_0001_0001 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
 d) Flagging data
 -------------------------------------------
 Dealing with sensorgroup which starts with LEMI025
 -------------------------------------------
Using the following parameter: keys=['x', 'y', 'z'],threshold=6,window=None,limits=[None, None]
   -> Found ['LEMI025_22_0002_0001', 'LEMI025_22_0002_0002', 'LEMI025_22_0003_0001', 'LEMI025_22_0003_0002', 'LEMI025_1_0001_0001', 'LEMI025_1_0001_0002', 'LEMI025_28_0002_0001', 'LEMI025_28_0002_0002', 'LEMI025_28_0002_0003', 'LEMI025_28_0002_0004', 'LEMI025_28_0002_0005']
 a) select 1 second or highest resolution data
Sensor: LEMI025_22_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI025_22_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI025_22_0003_0001 -> Samplingrate: 0.1
Sensor: LEMI025_22_0003_0002 -> Samplingrate: 1.0
Sensor: LEMI025_1_0001_0001 -> Samplingrate: 0.1
Sensor: LEMI025_1_0001_0002 -> Samplingrate: 1.0
Sensor: LEMI025_28_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI025_28_0002_0003 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0004 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0005 -> Samplingrate: 0.1
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for LEMI025_22_0003_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for LEMI025_22_0003
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with LEMI036
 -------------------------------------------
Using the following parameter: keys=['x', 'y', 'z'],threshold=6,window=None,limits=[None, None]
   -> Found ['LEMI036_1_0002_0001', 'LEMI036_1_0002_0002', 'LEMI036_3_0001_0001', 'LEMI036_3_0001_0002']
 a) select 1 second or highest resolution data
Sensor: LEMI036_1_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI036_1_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI036_3_0001_0001 -> Samplingrate: 0.1
Sensor: LEMI036_3_0001_0002 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for LEMI036_1_0002_0002
   Valid data for LEMI036_3_0001_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for LEMI036_1_0002
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
   - got 7200 datapoints
   - getting existing flags for LEMI036_3_0001
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with POS1
 -------------------------------------------
Using the following parameter: keys=['f'],threshold=4,window=0:01:40,limits=[None, None]
   -> Found ['POS1_N432_0001_0001', 'POS1_N456_0001_0001']
 a) select 1 second or highest resolution data
Sensor: POS1_N432_0001_0001 -> Samplingrate: 5.0
Sensor: POS1_N456_0001_0001 -> Samplingrate: 5.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
 d) Flagging data
 -------------------------------------------
 Dealing with sensorgroup which starts with BM35
 -------------------------------------------
Using the following parameter: keys=['var3'],threshold=None,window=None,limits=[750, 1000]
   -> Found ['BM35_033_0001_0001', 'BM35_033_0001_0002', 'BM35_029_0001_0001', 'BM35_029_0001_0002']
 a) select 1 second or highest resolution data
Sensor: BM35_033_0001_0001 -> Samplingrate: 0.488
Sensor: BM35_033_0001_0002 -> Samplingrate: 1.0
Sensor: BM35_029_0001_0001 -> Samplingrate: 0.498
Sensor: BM35_029_0001_0002 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for BM35_029_0001_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for BM35_029_0001
   - found 0 existing flags
  - flagging data below lower limit
  - flagging data above higher limit
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup which starts with GSM90_3
 -------------------------------------------
Using the following parameter: keys=['f'],threshold=5,window=0:05:00,limits=[None, None]
   -> Found ['GSM90_31968_0002_0001']
 a) select 1 second or highest resolution data
Sensor: GSM90_31968_0002_0001 -> Samplingrate: 4.007
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_31968_0002_0001
 d) Flagging data
   - got 1796 datapoints
   - getting existing flags for GSM90_31968_0002
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
------------------------------------------
 Step1 flagging finished
------------------------------------------
Cleaning up all records
##########################################
           Flaglist statistics            
##########################################

A) Total contents: 327160

B) Content for each ID:
Dataset: GSM90_14245_0002-LEMI025_22_0003 	 Amount: 2
Dataset: GP20S3EWS2_111201_0001 	 Amount: 5
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A7 	 Amount: 6
Dataset: BLV_LEMI025_22_0003_GSM90_6107631_0001_A2 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 	 Amount: 6
Dataset: BLV_LEMI025_22_0003_GP20S3NSS2_012201_0001_H1 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A7 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_H1 	 Amount: 6
Dataset: POS1_N432_0001-GSM90_14245_0002 	 Amount: 9
Dataset: LEMI036_1_0002-LEMI025_22_0002 	 Amount: 9
Dataset: BLV_LEMI025_22_0003_GSM90_14245_0002_A2 	 Amount: 12
Dataset: BLV_FGE_S0252_0001_POS1_N432_0001_A16 	 Amount: 14
Dataset: BLV_LEMI025_22_0003_GP20S3NSS2_012201_0001_A2 	 Amount: 18
Dataset: BM35_033_0001 	 Amount: 21
Dataset: BM35_029_0001 	 Amount: 23
Dataset: BLV_LEMI036_1_0002_POS1_N432_0001_A2 	 Amount: 24
Dataset: BLV_FGE_S0252_0001_POS1_N432_0001_A2 	 Amount: 27
Dataset: BLV_FGE_S0252_0001_GSM90_14245_0002_A2 	 Amount: 30
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A16 	 Amount: 30
Dataset: BLV_LEMI025_22_0002_POS1_N432_0001_A2 	 Amount: 36
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A2 	 Amount: 42
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A2 	 Amount: 48
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A16 	 Amount: 66
Dataset: GSM-19W_3101329_0001 	 Amount: 256
Dataset: GP20S3V_911005_0001 	 Amount: 399
Dataset: GSM90_6107631_0001 	 Amount: 1215
Dataset: FGE_S0252_0001 	 Amount: 1445
Dataset: POS1_N432_0001 	 Amount: 2949
Dataset: GSM90_31968_0002 	 Amount: 3236
Dataset: LEMI025_22_0002 	 Amount: 4682
Dataset: GP20S3NSS2_012201_0001 	 Amount: 4836
Dataset: POS1_N456_0001 	 Amount: 11983
Dataset: GSM90_6107632_0001 	 Amount: 12785
Dataset: GSM90_14245_0002 	 Amount: 14965
Dataset: GP20S3NS_012201_0001 	 Amount: 18806
Dataset: LEMI025_28_0002 	 Amount: 20446
Dataset: LEMI036_1_0002 	 Amount: 24439
Dataset: LEMI025_22_0003 	 Amount: 24468
Dataset: LEMI036_3_0001 	 Amount: 79488
Dataset: RCST7_20160114_0001 	 Amount: 100310

Logfile /var/log/magpy/mm-dp-flagging.log loaded
Existing: SAGITTARIUS-DataProducts-flagging-step1
Sat May 30 03:31:05 UTC 2020
3. Running magnetic analysis
r wic20200508qsec.sec'
*resp* '150 Opening BINARY mode data connection for wic20200508qmin.min'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
  -> Answer: False
  -- Uploading minute data to GIN: 20200508
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
*resp* '221 Goodbye.'
  -> Answer: True
Uploading QD data for 20200507
  -- THREAD for IAGA qsec data to FTP: 20200507
  -- THREAD for IAGA qmin data to FTP: 20200507
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
  -- Uploading second data to GIN - active now
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/quasidefinitive/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/quasidefinitive/'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200507qsec.sec'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200507qmin.min'
*resp* '550 wic20200507qsec.sec: No such file or directory'
*cmd* 'TYPE I'
*resp* '550 wic20200507qmin.min: No such file or directory'
*cmd* 'TYPE I'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '227 Entering Passive Mode (138,22,188,129,142,106).'
*cmd* u'STOR wic20200507qsec.sec'
*resp* '150 Opening BINARY mode data connection for wic20200507qsec.sec'
*resp* '227 Entering Passive Mode (138,22,188,129,173,159).'
*cmd* u'STOR wic20200507qmin.min'
*resp* '150 Opening BINARY mode data connection for wic20200507qmin.min'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
  -> Answer: True
  -- Uploading minute data to GIN: 20200507
  -> Answer: True
Uploading QD data fGetuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary DB at 138.22.188.195 ...
...success
Connecting also secondary DB at 138.22.188.191 ...
...success
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
----------------------------------------------------------------
Part 1: Create adjusted one second data from primary instruments
----------------------------------------------------------------
 a) get primary instruments
Found LEMI036_1_0002_0002 as primary variometer and GP20S3NSS2_012201_0001_0001 as scalar instrument
 b) getting variometer data, applying flags, offsets, WGS coordinates LEMI036_1_0002_0002
readDB: Read rows: 185416
     -- getting flags from DB: 0
   -- applying deltas
applyDeltas: No delta values found - returning unmodified stream
   -- offsets
  - applying compensation fields: x=-20.7425, y=0.0, z=-43.865
  -- rotation
Found rotation angle of -0.582
  - applying rotation: alpha=-0.582 determined in 2018
 c) getting scaladata, flags and offsets: GP20S3NSS2_012201_0001_0001
readDB: Read rows: 185433
readDB: could not identify time! Column sectime contains None, which cannot be interpreted as time by the testtime method
readDB: Found identical values only:sectime
('Test', array([ array([ 737573.00000337,  737573.0000149 ,  737573.00002642, ...,
        737575.14625137,  737575.14626325,  737575.14627462]),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64),
       array([ 48731.66758 ,  48731.665624,  48731.665119, ...,  48739.189584,
        48739.176836,  48739.169127]),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64)], dtype=object))
     -- obtained data - last F = 48739.169127
     -- getting flags from DB: 0
     -- applying deltasB:
     -- corrections performed -last F = 48737.598127
 d) performing simple baseline correction based on pier A2
    LEMI036_1_0002_0002 and GP20S3NSS2_012201_0001_0001
    using BLV data
  - Found 6 flags for baseline values
  - Basevalues for last 100 days:
  - Delta H = 24.7997124058 +/- 0.889590991626
  - Delta D = 4.25264308787 +/- 0.0009288673232
  - Delta Z = -20.0830980966 +/- 0.403744364518
  - Running Analysis jobs ... 
Key data_threshold_amount_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
Key data_actuality_time_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
Key data_threshold_base_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
  - Performing constant basevalue correction
 e) combining data sets, adding header, writing sec and min data
mergeStreams: Found identical timesteps - using simple merge
('  - preliminary data file after MERGE:', [185416, 185416, 185416, 185416, 185416, 185416, 185416, 0, 185416, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
  - Saving one second data - IAGA
  - Saving one second data - CDF
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
185416
  - Saving one minute data - IAGA
  - Saving one minute adjusted data to database
Writing adjusted data to primary DB
Writing adjusted data to secondary DB
-----------------------------------
Part1 needs 0:00:56.707071
-----------------------------------
----------------------------------------------------------------
Part 2: Publish adjusted data
----------------------------------------------------------------
  uploading one second data to ZAMG Server and eventually to GIN
Uploading data for 20200530
  -- THREAD for IAGA data to FTP: 20200530
('Submitting to gin if no other curl job detected: active_pid = ', True)
#################################
*cmd* 'USER trmsoe@www.zamg.ac.at'
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
 !!!!!!!!!!!!! curl still active sending data in next round
Uploading data for 20200528
  -- THREAD for IAGA data to FTP: 20200528
('Submitting to gin if no other curl job detected: active_pid = ', True)
#################################
*cmd* 'USER trmsoe@www.zamg.ac.at'
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
 !!!!!!!!!!!!! curl still active sending data in next round
----------------------------------------------------------------
Part 3: determine quasidefinite data
----------------------------------------------------------------
  - Current weekday: 5
 a) Checking whether current time is suitable for QD
    - QD calculation will be performed on day 5 between 3:00 and 4:00
  - Running Quasidefinitve data determinations - checking for new flags
 b) QD time - checking actuality of flags
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200528psec.sec'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200530psec.sec'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200530pmin.min'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200528pmin.min'
*resp* '250 DELE command successful'
*resp* '250 DELE command successful'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*cmd* 'TYPE I'
*cmd* *resp* '250 DELE command successful'
'TYPE I'
*cmd* 'TYPE I'
     -- found flags: 29275
     -- last flag modification with ID 2 or 3 at 2020-05-28 15:37:34.781630
 - Found new flags -> assuming QD conditions for the week before
 c) suitable QD time and flags found - now checking whether QD determination has already been performed within the current time period
    - last analysis performed on 2020-05-30 (today: 2020-05-30)
  -> QD determination already performed (or tried) in this period
-----------------------------------
Part3 needs 0:00:06.120675
-----------------------------------
----------------------------------------------------------------
Part 5: create plots and upload them to webpage
----------------------------------------------------------------
('Part5 - Creating plot:', u'LEMI036_1_0002_0002', u'GP20S3NSS2_012201_0001_0001')
 - Saving diagram to products folder
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '200 Type set to I'
*cmd* 'PASV'
 - kvalues
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
ndtype - Timeseries ending at: 2020-05-30 03:30:00+00:00
Coverage in days: 2.14583333337
Last effective time series ending at day 2020-05-30 00:00:00
 -----------------------------------------------------
 ------------- Starting backward analysis ------------
 --------------- beginning at last time --------------
Step0 needed: 0:00:00.000131
Step1 needed: 0:00:00.003444
Step2 needed: 0:00:00.545908
Step3 needed: 0:00:00.005764
*resp* '227 Entering Passive Mode (138,22,188,129,141,52).'
*resp* '227 Entering Passive Mode (138,22,188,129,158,154).'
*cmd* u'STOR wic20200530pmin.min'
*cmd* u'STOR wic20200530psec.sec'
Step4 needed: 0:00:00.543894
Step5 needed: 0:00:00.005759
 -----------------------------------------------------
 ------------- Starting forward analysis -------------
 -----------------  from first date ------------------
Running daily chunks forward until  2020-05-29 00:00:00+00:00
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not corre/home/cobs/anaconda2/lib/python2.7/site-packages/magpy/database.py:1974: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if not col[0] or col[0] in ['nan', '-','']: #remove place holders
ctly determinable for day 2020-05-28 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
*resp* '150 Opening BINARY mode data connection for wic20200530pmin.min'
*resp* '150 Opening BINARY mode data connection for wic20200530psec.sec'
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
Running daily chunks forward until  2020-05-30 00:00:00+00:00
*resp* '227 Entering Passive Mode (138,22,188,129,160,199).'
*cmd* u'STOR wic20200528pmin.min'
*resp* '227 Entering Passive Mode (138,22,188,129,138,133).'
*cmd* u'STOR wic20200528psec.sec'
Checking kvals
Index: 0, time: 2020-05-28 19:30:00+00:00, kval: 0
Index: 1, time: 2020-05-28 22:30:00+00:00, kval: 1
Index: 2, time: 2020-05-29 01:30:00+00:00, kval: 1
Index: 3, time: 2020-05-29 04:30:00+00:00, kval: 1
Index: 4, time: 2020-05-29 07:30:00+00:00, kval: 1
Index: 5, time: 2020-05-29 10:30:00+00:00, kval: 1
Index: 6, time: 2020-05-29 13:30:00+00:00, kval: 1
Index: 7, time: 2020-05-29 16:30:00+00:00, kval: 1
Index: 8, time: 2020-05-29 19:30:00+00:00, kval: 1
Index: 9, time: 2020-05-29 22:30:00+00:00, kval: 2
Index: 10, time: 2020-05-30 01:30:00+00:00, kval: 2
Index: 11, time: 2020-05-30 04:30:00+00:00, kval: 1
11
None
Expect k of 1 until 2020-05-30 04:30 + 1.5 hours UTC (current time = 2020-05-30 03:32:13.205274)
K value has been updated to 1
  -> Now writing kvals to database
  -> Done
  -> Now writing kvals to secondary database
  -> Done
 -- Starting scptransfer with timeout 300
*resp* '150 Opening BINARY mode data connection for wic20200528pmin.min'
*resp* '150 Opening BINARY mode data connection for wic20200528psec.sec'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
 
magvar_2020-05-30.png                           0%    0     0.0KB/s   --:-- ETAmagvar_2020-05-30.png                         100%   98KB  98.2KB/s   00:00    

 -- now removing temporary file...
  - Uploading of plots successful
-----------------------------------
All Parts needed: 0:01:35.063087
-----------------------------------
{'SAGITTARIUS-DataProducts-magnetism-step5a': 'creating and saving graph successful', 'SAGITTARIUS-DataProducts-magnetism-step5b': 'determinig k successfull', 'SAGITTARIUS-DataProducts-magnetism-step3b': 'last quasidefinitive calculation successful', 'SAGITTARIUS-DataProducts-magnetism-step3c': 'qd coverage ok', 'SAGITTARIUS-DataProducts-magnetism-step3a': 'last suitability test for quasidefinitive finished', 'SAGITTARIUS-DataProducts-magnetism-step4': 'last upload of QD successful', 'SAGITTARIUS-DataProducts-magnetism-step5': 'uploading plots successful', 'SAGITTARIUS-DataProducts-magnetism-step2': 'upload successful', 'SAGITTARIUS-DataProducts-magnetism-obligatory directories': 'all accessible', 'SAGITTARIUS-DataProducts-magnetisor 20200506
  -- THREAD for IAGA qsec data to FTP: 20200506
  -- THREAD for IAGA qmin data to FTP: 20200506
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
  -- Uploading second data to GIN - active now
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/quasidefinitive/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/quasidefinitive/'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200506qmin.min'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200506qsec.sec'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*resp* '227 Entering Passive Mode (138,22,188,129,149,115).'
*cmd* u'STOR wic20200506qmin.min'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '150 Opening BINARY mode data connection for wic20200506qmin.min'
*resp* '227 Entering Passive Mode (138,22,188,129,168,150).'
*cmd* u'STOR wic20200506qsec.sec'
*resp* '150 Opening BINARY mode data connection for wic20200506qsec.sec'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
  -> Answer: False
  -- Uploading minute data to GIN: 20200506
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
  -> Answer: False
 !!!!!!!!!!!!!!! QD data upload failed
----------------------------------------------------------------
Part 5: create plots and upload them to webpage
----------------------------------------------------------------
('Part5 - Creating plot:', u'LEMI036_1_0002_0002', u'GP20S3NSS2_012201_0001_0001')
 - Saving diagram to products folder
 - kvalues
-------------------------
Dealing with key:/home/cobs/anaconda2/lib/python2.7/site-packages/magpy/database.py:1974: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if not col[0] or col[0] in ['nan', '-','']: #remove place holders
 x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
ndtype - Timeseries ending at: 2020-05-30 03:00:00+00:00
Coverage in days: 2.125
Last effective time series ending at day 2020-05-30 00:00:00
 -----------------------------------------------------
 ------------- Starting backward analysis ------------
 --------------- beginning at last time --------------
Step0 needed: 0:00:00.000147
Step1 needed: 0:00:00.003100
Step2 needed: 0:00:00.530448
Step3 needed: 0:00:00.005415
Step4 needed: 0:00:00.521605
Step5 needed: 0:00:00.005236
 -----------------------------------------------------
 ------------- Starting forward analysis -------------
 -----------------  from first date ------------------
Running daily chunks forward until  2020-05-29 00:00:00+00:00
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-28 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
Running daily chunks forward until  2020-05-30 00:00:00+00:00
Checking kvals
Index: 0, time: 2020-05-28 19:30:00+00:00, kval: 0.0
Index: 1, time: 2020-05-28 22:30:00+00:00, kval: 1.0
Index: 2, time: 2020-05-29 01:30:00+00:00, kval: 1.0
Index: 3, time: 2020-05-29 04:30:00+00:00, kval: 1.0
Index: 4, time: 2020-05-29 07:30:00+00:00, kval: 1.0
Index: 5, time: 2020-05-29 10:30:00+00:00, kval: 1.0
Index: 6, time: 2020-05-29 13:30:00+00:00, kval: 1.0
Index: 7, time: 2020-05-29 16:30:00+00:00, kval: 1.0
Index: 8, time: 2020-05-29 19:30:00+00:00, kval: 1.0
Index: 9, time: 2020-05-29 22:30:00+00:00, kval: 2.0
Index: 10, time: 2020-05-30 01:30:00+00:00, kval: 2.0
10
None
Expect k of 2.0 until 2020-05-30 01:30 + 1.5 hours UTC (current time = 2020-05-30 03:32:59.485669)
K value has been updated to 2.0
  -> Now writing kvals to database
  -> Done
  -> Now writing kvals to secondary database
  -> Done
 -- Starting scptransfer with timeout 300
 
magvar_2020-05-30.png                           0%    0     0.0KB/s   --:-- ETAmagvar_2020-05-30.png                         100%   98KB  98.0KB/s   00:00    

 -- now removing temporary file...
  - Uploading of plots successful
-----------------------------------
All Parts needed: 0:32:22.573637
-----------------------------------
{'SAGITTARIUS-DataProducts-magnetism-step5a': 'creating and saving graph 