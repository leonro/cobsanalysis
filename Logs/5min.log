Fri May 29 14:30:01 UTC 2020
1. Identify primary instrument
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary MARCOS...
('Checking ', 'LEMI036_1_0002_0002')
(86400, '2020-05-29 14:25:16.000000', '2020-05-28 14:25:17.000000')
(datetime.datetime(2020, 5, 29, 14, 25, 16), datetime.datetime(2020, 5, 28, 14, 25, 17))
Coverage OK - using LEMI036_1_0002_0002
('Checking ', 'GP20S3NSS2_012201_0001_0001')
(86400, datetime.datetime(2020, 5, 29, 14, 25, 45, 694787))
Test 1 OK: data  available and last value not null
(datetime.datetime(2020, 5, 29, 14, 25, 45, 694787), datetime.datetime(2020, 5, 28, 14, 25, 34, 690793))
Test 2 OK: correct amount of data covering the last day
Get primary -> Using Variometer LEMI036_1_0002_0002 and Scalar GP20S3NSS2_012201_0001_0001
Dumping instruments as usual in the old way...
... done
('Got', {u'magnetism': {u'QD enddate': [u'2020-05-06', u''], u'k-warning': [0, u''], u'k': [1.0, u''], u'primary scalar': [u'GP20S3NSS2_012201_0001_0001', u''], u'k-time': [u'2020-05-29 13:30', u''], u'k-valid': [u'', u''], u'primary vario': [u'LEMI036_1_0002_0002', u'']}, u'logging': {u'magnetismplots': [u'2020-05-29 14:23', u''], u'seismoNEICdata': [u'2020-05-28 23:41', u''], u'seismoATdata': [u'2020-05-29 14:21', u''], u'failedupload2homepage': 0}})
Logfile /var/log/magpy/mm-dp-getprimary.log loaded
Existing: SAGITTARIUS-DataProducts-getprimary-vario
Existing: SAGITTARIUS-DataProducts-getprimary-process
Existing: SAGITTARIUS-DataProducts-getprimary-scalar
Existing: SAGITTARIUS-DataProducts-getprimary-write
Fri May 29 14:30:04 UTC 2020
2. Automatic flags
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary MARCOS...
...success
 -------------------------------------------
 Dealing with sensorgroup GSM90_6
 -------------------------------------------
0:05:00
   -> Found ['GSM90_6107631_0001_0001', 'GSM90_6107632_0001_0001']
 a) select 1 second or highest resolution data
Sensor: GSM90_6107631_0001_0001 -> Samplingrate: 3.0
Sensor: GSM90_6107632_0001_0001 -> Samplingrate: 3.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_6107631_0001_0001
   Valid data for GSM90_6107632_0001_0001
 d) Flagging data
   - got 2400 datapoints
   - getting existing flags for GSM90_6107631_0001
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
   - got 2400 datapoints
   - getting existing flags for GSM90_6107632_0001
   - found 1 existing flags
  - removing existing flags
    ...success
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup GP20S3NSS2
 -------------------------------------------
None
   -> Found ['GP20S3NSS2_012201_0001_0001']
 a) select 1 second or highest resolution data
Sensor: GP20S3NSS2_012201_0001_0001 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GP20S3NSS2_012201_0001_0001
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for GP20S3NSS2_012201_0001
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup GSM90_14245
 -------------------------------------------
None
   -> Found ['GSM90_14245_0002_0001', 'GSM90_14245_0002_0002', 'GSM90_14245_0002_0003']
 a) select 1 second or highest resolution data
Sensor: GSM90_14245_0002_0001 -> Samplingrate: 0.2
Sensor: GSM90_14245_0002_0002 -> Samplingrate: 1.0
Sensor: GSM90_14245_0002_0003 -> Samplingrate: 0.5
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_14245_0002_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for GSM90_14245_0002
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup FGE
 -------------------------------------------
None
   -> Found ['FGE_S0252_0001_0001']
 a) select 1 second or highest resolution data
Sensor: FGE_S0252_0001_0001 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
 d) Flagging data
 -------------------------------------------
 Dealing with sensorgroup LEMI025
 -------------------------------------------
None
   -> Found ['LEMI025_22_0002_0001', 'LEMI025_22_0002_0002', 'LEMI025_22_0003_0001', 'LEMI025_22_0003_0002', 'LEMI025_1_0001_0001', 'LEMI025_1_0001_0002', 'LEMI025_28_0002_0001', 'LEMI025_28_0002_0002', 'LEMI025_28_0002_0003', 'LEMI025_28_0002_0004', 'LEMI025_28_0002_0005']
 a) select 1 second or highest resolution data
Sensor: LEMI025_22_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI025_22_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI025_22_0003_0001 -> Samplingrate: 0.1
Sensor: LEMI025_22_0003_0002 -> Samplingrate: 1.0
Sensor: LEMI025_1_0001_0001 -> Samplingrate: 0.1
Sensor: LEMI025_1_0001_0002 -> Samplingrate: 1.0
Sensor: LEMI025_28_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI025_28_0002_0003 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0004 -> Samplingrate: 0.1
Sensor: LEMI025_28_0002_0005 -> Samplingrate: 0.1
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for LEMI025_22_0003_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for LEMI025_22_0003
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup LEMI036
 -------------------------------------------
None
   -> Found ['LEMI036_1_0002_0001', 'LEMI036_1_0002_0002', 'LEMI036_3_0001_0001', 'LEMI036_3_0001_0002']
 a) select 1 second or highest resolution data
Sensor: LEMI036_1_0002_0001 -> Samplingrate: 0.1
Sensor: LEMI036_1_0002_0002 -> Samplingrate: 1.0
Sensor: LEMI036_3_0001_0001 -> Samplingrate: 0.1
Sensor: LEMI036_3_0001_0002 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for LEMI036_1_0002_0002
   Valid data for LEMI036_3_0001_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for LEMI036_1_0002
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
   - got 7200 datapoints
   - getting existing flags for LEMI036_3_0001
   - found 0 existing flags
  - determining new outliers
True
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
  - new flags: 0
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup POS1
 -------------------------------------------
0:01:40
   -> Found ['POS1_N432_0001_0001', 'POS1_N456_0001_0001']
 a) select 1 second or highest resolution data
Sensor: POS1_N432_0001_0001 -> Samplingrate: 5.0
Sensor: POS1_N456_0001_0001 -> Samplingrate: 5.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
 d) Flagging data
 -------------------------------------------
 Dealing with sensorgroup BM35
 -------------------------------------------
None
   -> Found ['BM35_033_0001_0001', 'BM35_033_0001_0002', 'BM35_029_0001_0001', 'BM35_029_0001_0002']
 a) select 1 second or highest resolution data
Sensor: BM35_033_0001_0001 -> Samplingrate: 0.488
Sensor: BM35_033_0001_0002 -> Samplingrate: 1.0
Sensor: BM35_029_0001_0001 -> Samplingrate: 0.498
Sensor: BM35_029_0001_0002 -> Samplingrate: 1.0
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for BM35_029_0001_0002
 d) Flagging data
   - got 7200 datapoints
   - getting existing flags for BM35_029_0001
   - found 0 existing flags
  - flagging data below lower limit
  - flagging data above higher limit
RESULT: found [] new flags
 -------------------------------------------
 Dealing with sensorgroup GSM90_3
 -------------------------------------------
0:05:00
   -> Found ['GSM90_31968_0002_0001']
 a) select 1 second or highest resolution data
Sensor: GSM90_31968_0002_0001 -> Samplingrate: 4.007
 b) checking sampling rate of failed sensors
 c) Check for recent data
   Valid data for GSM90_31968_0002_0001
 d) Flagging data
   - got 1796 datapoints
   - getting existing flags for GSM90_31968_0002
   - found 0 existing flags
  - determining new outliers
False
-------------------------
Dealing with key: f
  - new flags: 0
RESULT: found [] new flags
------------------------------------------
 Step1 flagging finished
------------------------------------------
Cleaning up all records
##########################################
           Flaglist statistics            
##########################################

A) Total contents: 326313

B) Content for each ID:
Dataset: GSM90_14245_0002-LEMI025_22_0003 	 Amount: 2
Dataset: GP20S3EWS2_111201_0001 	 Amount: 5
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A7 	 Amount: 6
Dataset: BLV_LEMI025_22_0003_GSM90_6107631_0001_A2 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 	 Amount: 6
Dataset: BLV_LEMI025_22_0003_GP20S3NSS2_012201_0001_H1 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A7 	 Amount: 6
Dataset: BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_H1 	 Amount: 6
Dataset: POS1_N432_0001-GSM90_14245_0002 	 Amount: 9
Dataset: LEMI036_1_0002-LEMI025_22_0002 	 Amount: 9
Dataset: BLV_LEMI025_22_0003_GSM90_14245_0002_A2 	 Amount: 12
Dataset: BLV_FGE_S0252_0001_POS1_N432_0001_A16 	 Amount: 14
Dataset: BLV_LEMI025_22_0003_GP20S3NSS2_012201_0001_A2 	 Amount: 18
Dataset: BM35_033_0001 	 Amount: 21
Dataset: BM35_029_0001 	 Amount: 23
Dataset: BLV_LEMI036_1_0002_POS1_N432_0001_A2 	 Amount: 24
Dataset: BLV_FGE_S0252_0001_POS1_N432_0001_A2 	 Amount: 27
Dataset: BLV_FGE_S0252_0001_GSM90_14245_0002_A2 	 Amount: 30
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A16 	 Amount: 30
Dataset: BLV_LEMI025_22_0002_POS1_N432_0001_A2 	 Amount: 36
Dataset: BLV_LEMI036_1_0002_GSM90_14245_0002_A2 	 Amount: 42
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A2 	 Amount: 48
Dataset: BLV_LEMI025_22_0002_GSM90_14245_0002_A16 	 Amount: 66
Dataset: GSM-19W_3101329_0001 	 Amount: 256
Dataset: GP20S3V_911005_0001 	 Amount: 399
Dataset: GSM90_6107631_0001 	 Amount: 1215
Dataset: FGE_S0252_0001 	 Amount: 1445
Dataset: POS1_N432_0001 	 Amount: 2949
Dataset: GSM90_31968_0002 	 Amount: 3236
Dataset: LEMI025_22_0002 	 Amount: 4682
Dataset: GP20S3NSS2_012201_0001 	 Amount: 4836
Dataset: POS1_N456_0001 	 Amount: 11983
Dataset: GSM90_6107632_0001 	 Amount: 12752
Dataset: GSM90_14245_0002 	 Amount: 14965
Dataset: GP20S3NS_012201_0001 	 Amount: 18806
Dataset: LEMI025_28_0002 	 Amount: 20446
Dataset: LEMI036_1_0002 	 Amount: 24439
Dataset: LEMI025_22_0003 	 Amount: 24468
Dataset: LEMI036_3_0001 	 Amount: 79488
Dataset: RCST7_20160114_0001 	 Amount: 99496

Logfile /var/log/magpy/mm-dp-flagging.log loaded
Existing: SAGITTARIUS-DataProducts-flagging-step1
Fri May 29 14:31:13 UTC 2020
3. Running magnetic analysis
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary DB at 138.22.188.195 ...
...success
Connecting also secondary DB at 138.22.188.191 ...
...success
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
----------------------------------------------------------------
Part 1: Create adjusted one second data from primary instruments
----------------------------------------------------------------
 a) get primary instruments
Found LEMI036_1_0002_0002 as primary variometer and GP20S3NSS2_012201_0001_0001 as scalar instrument
 b) getting variometer data, applying flags, offsets, WGS coordinates LEMI036_1_0002_0002
readDB: Read rows: 225016
     -- getting flags from DB: 120
Flag: 20 percent done
Flag: 40 percent done
Flag: 60 percent done
Flag: 80 percent done
   -- applying deltas
applyDeltas: No delta values found - returning unmodified stream
   -- offsets
  - applying compensation fields: x=-20.7425, y=0.0, z=-43.865
  -- rotation
Found rotation angle of -0.582
  - applying rotation: alpha=-0.582 determined in 2018
 c) getting scaladata, flags and offsets: GP20S3NSS2_012201_0001_0001
readDB: Read rows: 225029
readDB: could not identify time! Column sectime contains None, which cannot be interpreted as time by the testtime method
readDB: Found identical values only:sectime
('Test', array([ array([ 737572.00000365,  737572.00001508,  737572.00002676, ...,
        737574.60457946,  737574.60459114,  737574.60460292]),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64),
       array([ 48731.417654,  48731.413698,  48731.409699, ...,  48726.165505,
        48726.164521,  48726.166098]),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64), array([], dtype=float64),
       array([], dtype=float64)], dtype=object))
     -- obtained data - last F = 48726.166098
     -- getting flags from DB: 36
     -- applying deltasB:
     -- corrections performed -last F = 48724.595098
 d) performing simple baseline correction based on pier A2
    LEMI036_1_0002_0002 and GP20S3NSS2_012201_0001_0001
    using BLV data
  - Found 6 flags for baseline values
  - Basevalues for last 100 days:
  - Delta H = 24.7997124058 +/- 0.889590991626
  - Delta D = 4.25264308787 +/- 0.0009288673232
  - Delta Z = -20.0830980966 +/- 0.403744364518
  - Running Analysis jobs ... 
Key data_threshold_amount_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
Key data_actuality_time_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
Key data_threshold_base_BLV_LEMI036_1_0002_GP20S3NSS2_012201_0001_A2 already contained in loglist - checking status
-> Status remaining unchanged
  - Performing constant basevalue correction
 e) combining data sets, adding header, writing sec and min data
mergeStreams: Found identical timesteps - using simple merge
('  - preliminary data file after MERGE:', [225016, 225016, 225016, 225016, 225016, 225016, 225016, 0, 225016, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
  - Saving one second data - IAGA
  - Saving one second data - CDF
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
writeIMAGCDF: current Publication level 2 does not allow to set StandardName
writeIMAGCDF: Found F column
writeIMAGCDF: given components are XYZF. Checking F column...
writeIMAGCDF: analyzed F column - values are apparently independend from vector components - using column name 'S'
225016
  - Saving one minute data - IAGA
  - Saving one minute adjusted data to database
Writing adjusted data to primary DB
Writing adjusted data to secondary DB
-----------------------------------
Part1 needs 0:01:28.299993
-----------------------------------
----------------------------------------------------------------
Part 2: Publish adjusted data
----------------------------------------------------------------
  uploading one second data to ZAMG Server and eventually to GIN
Uploading data for 20200529
  -- THREAD for IAGA data to FTP: 20200529
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
('Submitting to gin if no other curl job detected: active_pid = ', False)
#################################
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
  -- Uploading second data to GIN - active now
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200529psec.sec'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200529pmin.min'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '227 Entering Passive Mode (138,22,188,129,138,229).'
*cmd* u'STOR wic20200529pmin.min'
*resp* '150 Opening BINARY mode data connection for wic20200529pmin.min'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '227 Entering Passive Mode (138,22,188,129,159,231).'
*cmd* u'STOR wic20200529psec.sec'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '150 Opening BINARY mode data connection for wic20200529psec.sec'
*resp* '221 Goodbye.'
Exception
Unable to access database

Exception details:
Exception: uk.ac.bgs.GINFileUpload.Model.MetadataBackingStoreException
  Message: Unable to access database
  Stack trace:
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:311)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)

Root cause
Exception: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException
  Message: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by 'SQL180321141534320' defined on 'GINFILEUPLOAD'.
  Stack trace:
    org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeLargeUpdate(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLLoggingPreparedStatement.executeUpdate(SQLLoggingPreparedStatement.java:147)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:300)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)

Root cause
Exception: org.apache.derby.iapi.error.StandardException
  Message: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by 'SQL180321141534320' defined on 'GINFILEUPLOAD'.
  Stack trace:
    org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.doInsert(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.insert(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexSetChanger.insert(Unknown Source)
    org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(Unknown Source)
    org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)
    org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
    org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
    org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeLargeUpdate(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLLoggingPreparedStatement.executeUpdate(SQLLoggingPreparedStatement.java:147)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:300)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)
   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100   994  100   994    0     0   1305      0 --:--:-- --:--:-- --:--:--  1304
  0 3673k    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0 58 3673k    0     0   58 2160k      0   924k  0:00:03  0:00:02  0:00:01 3529k 61 3673k    0     0   61 2272k      0   676k  0:00:05  0:00:03  0:00:02 1389k 61 3673k    0     0   61 2272k      0   521k  0:00:07  0:00:04  0:00:03  861k 61 3673k    0     0   61 2272k      0   423k  0:00:08  0:00:05  0:00:03  624k 64 3673k    0     0   64 2368k      0   361k  0:00:10  0:00:06  0:00:04  491k 65 3673k    0     0   65 2416k      0   320k  0:00:11  0:00:07  0:00:04 50344 65 3673k    0     0   65 2416k      0   282k  0:00:12  0:00:08  0:00:04 28427 67 3673k    0     0   67 2496k      0   259k  0:00:14  0:00:09  0:00:05 43557 67 3673k    0     0   67 2496k      0   234k  0:00:15  0:00:10  0:00:05 43557 68 3673k    0     0   68 2528k      0   212k  0:00:17  0:00:11  0:00:06 30555 68 3673k    0     0   68 2528k      0   195k  0:00:18  0:00:12  0:00:06 21389 69 3673k    0     0   69 2544k      0   187k  0:00:19  0:00:13  0:00:06 26224 72 3673k    0     0   72 2656k      0   184k  0:00:19  0:00:14  0:00:05 34384 73 3673k    0     0   73 2688k      0   174k  0:00:21  0:00:15  0:00:06 41260 74 3673k    0     0   74 2736k      0   160k  0:00:22  0:00:17  0:00:05 41094 74 3673k    0     0   74 2752k      0   154k  0:00:23  0:00:17  0:00:06 46451 75 3673k    0     0   75 2768k      0   146k  0:00:25  0:00:18  0:00:07 43262 75 3673k    0     0   75 2768k      0   139k  0:00:26  0:00:19  0:00:07 21024 75 3673k    0     0   75 2784k      0   135k  0:00:27  0:00:20  0:00:07 19173 79 3673k    0     0   79 2912k      0   136k  0:00:26  0:00:21  0:00:05 42707 80 3673k    0     0   80 2960k      0   132k  0:00:27  0:00:22  0:00:05 47279 81 3673k    0     0   81 2976k      0   128k  0:00:28  0:00:23  0:00:05 48606 81 3673k    0     0   81 3008k      0   124k  0:00:29  0:00:24  0:00:05 56083 82 3673k    0     0   82 3040k      0   118k  0:00:30  0:00:25  0:00:05 51200 83 3673k    0     0   83 3056k      0   115k  0:00:31  0:00:26  0:00:05 28582 85 3673k    0     0   85 3136k      0   114k  0:00:32  0:00:27  0:00:05 35179 86 3673k    0     0   86 3184k      0   111k  0:00:32  0:00:28  0:00:04 39692 89 3673k    0     0   89 3296k      0   109k  0:00:33  0:00:29  0:00:04 51164 90 3673k    0     0   90 3312k      0   106k  0:00:34  0:00:30  0:00:04 52032 90 3673k    0     0   90 3328k      0   105k  0:00:34  0:00:31  0:00:03 53593 94 3673k    0     0   94 3472k      0   106k  0:00:34  0:00:32  0:00:02 68484 95 3673k    0     0   95 3520k      0   106k  0:00:34  0:00:33  0:00:01 75785 98 3673k    0     0   98 3600k      0   105k  0:00:34  0:00:34 --:--:-- 75101100 3673k    0     0  100 3673k      0   102k  0:00:35  0:00:35 --:--:-- 76632100 3673k    0     0  100 3673k      0    99k  0:00:36  0:00:36 --:--:-- 68535100 3673k    0     0  100 3673k      0  99447  0:00:37  0:00:37 --:--:-- 38662100 3673k    0     0  100 3673k      0  96882  0:00:38  0:00:38 --:--:-- 27545100 3673k    0     0  100 3673k      0  94446  0:00:39  0:00:39 --:--:-- 13160100 3673k    0     0  100 3673k      0  92129  0:00:40  0:00:40 --:--:--     0100 3673k    0     0  100 3673k      0  89924  0:00:41  0:00:41 --:--:--     0100 3673k    0     0  100 3673k      0  87822  0:00:42  0:00:42 --:--:--     0100 3673k    0     0  100 3673k      0  85815  0:00:43  0:00:43 --:--:--     0100 3673k    0     0  100 3673k      0  83899  0:00:44  0:00:44 --:--:--     0100 3673k    0     0  100 3673k      0  82066  0:00:45  0:00:45 --:--:--     0100 3673k    0     0  100 3673k      0  80311  0:00:46  0:00:46 --:--:--     0100 3673k    0     0  100 3673k      0  78630  0:00:47  0:00:47 --:--:--     0100 3673k    0     0  100 3673k      0  77018  0:00:48  0:00:48 --:--:--     0100 3673k    0     0  100 3673k      0  75471  0:00:49  0:00:49 --:--:--     0100 3673k    0     0  100 3673k      0  73984  0:00:50  0:00:50 --:--:--     0100 3673k    0     0  100 3673k      0  72555  0:00:51  0:00:51 --:--:--     0100 3673k    0     0  100 3673k      0  71180  0:00:52  0:00:52 --:--:--     0100 3673k    0     0  100 3673k      0  69857  0:00:53  0:00:53 --:--:--     0100 3673k    0     0  100 3673k      0  69044  0:00:54  0:00:54 --:--:--     0100 3683k    0 10276  100 3673k    188  68989  0:00:54  0:00:54 --:--:--     0

False
  -- Uploading minute data to GIN: 20200529
No faillog existing
Success
Data loaded OK, data file id = 33813159
   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0   994    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0100   994  100   994    0     0    857      0  0:00:01  0:00:01 --:--:--   857
  0 64551    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0100 64551    0     0  100 64551      0  19476  0:00:03  0:00:03 --:--:-- 56180100 64551    0     0  100 64551      0  14954  0:00:04  0:00:04 --:--:-- 30009100 64599  100    48  100 64551     11  14904  0:00:04  0:00:04 --:--:-- 29801

True
Uploading data for 20200527
  -- THREAD for IAGA data to FTP: 20200527
('Submitting to gin if no other curl job detected: active_pid = ', False)
#################################
  -- Uploading second data to GIN - active now
*cmd* 'USER trmsoe@www.zamg.ac.at'
*cmd* 'USER trmsoe@www.zamg.ac.at'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*resp* '331 Password required for trmsoe.'
*cmd* 'PASS *********'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* "230-- PASS for trmsoe@www.zamg.ac.at.\n 220- zagsvl24.zamg.ac.at PROXY-FTP server (DeleGate/9.9.13) ready.\n 220-   @ @\n 220-  ( - ) { DeleGate/9.9.13 (October 31, 2014) }\n 220- AIST-Product-ID: 2000-ETL-198715-01, H14PRO-049, H15PRO-165, H18PRO-443\n 220- Copyright (c) 1994-2000 Yutaka Sato and ETL,AIST,MITI\n 220- Copyright (c) 2001-2014 National Institute of Advanced Industrial Science and Technology (AIST)\n 220- WWW: http://www.delegate.org/delegate/\n 220- --\n 220- You can connect to a SERVER by `user' command:\n 220-    ftp> user username@SERVER\n 220- or by `cd' command (after logged in as an anonymous user):\n 220-    ftp> cd //SERVER\n 220- Cache is enabled by default and can be disabled by `cd .' (toggle)\n 220- This (proxy) service is maintained by 'Nikolaus.horn@zamg.ac.at'\n 220- \n 220-extended FTP [MODE XDC][XDC/BASE64]\n 220  \n 331 Password required for trmsoe.\n230-- PASS for trmsoe@www.zamg.ac.at.\n 220 ProFTPD 1.3.5 Server ready.\n 331 Password required for trmsoe\n230- User trmsoe logged in\n230--  @ @  \n230-  \\( - )/ -- { connected to `www.zamg.ac.at' }\n230--  @ @  \n230  \\( - )/ -- { connected to `www.zamg.ac.at' (via FTP-Proxy) }"
*cmd* 'CWD /data/magnetism/wic/variation/'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200527pmin.min'
*resp* '250 CWD command successful'
*cmd* 'DELE wic20200527psec.sec'
*resp* '250 DELE command successful'
*resp* '250 DELE command successful'
*cmd* 'TYPE I'
*cmd* 'TYPE I'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '200 Type set to I'
*cmd* 'PASV'
*resp* '227 Entering Passive Mode (138,22,188,129,161,223).'
*cmd* u'STOR wic20200527psec.sec'
*resp* '227 Entering Passive Mode (138,22,188,129,139,27).'
*cmd* u'STOR wic20200527pmin.min'
*resp* '150 Opening BINARY mode data connection for wic20200527psec.sec'
*resp* '150 Opening BINARY mode data connection for wic20200527pmin.min'
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
Exception
Unable to access database

Exception details:
Exception: uk.ac.bgs.GINFileUpload.Model.MetadataBackingStoreException
  Message: Unable to access database
  Stack trace:
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:311)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)

Root cause
Exception: org.apache.derby.shared.common.error.DerbySQLIntegrityConstraintViolationException
  Message: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by 'SQL180321141534320' defined on 'GINFILEUPLOAD'.
  Stack trace:
    org.apache.derby.impl.jdbc.SQLExceptionFactory.getSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.Util.generateCsSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.TransactionResourceImpl.wrapInSQLException(Unknown Source)
    org.apache.derby.impl.jdbc.TransactionResourceImpl.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedConnection.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.ConnectionChild.handleException(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeLargeUpdate(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLLoggingPreparedStatement.executeUpdate(SQLLoggingPreparedStatement.java:147)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:300)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)

Root cause
Exception: org.apache.derby.iapi.error.StandardException
  Message: The statement was aborted because it would have caused a duplicate key value in a unique or primary key constraint or unique index identified by 'SQL180321141534320' defined on 'GINFILEUPLOAD'.
  Stack trace:
    org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    org.apache.derby.iapi.error.StandardException.newException(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.insertAndCheckDups(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.doInsert(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexChanger.insert(Unknown Source)
    org.apache.derby.impl.sql.execute.IndexSetChanger.insert(Unknown Source)
    org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(Unknown Source)
    org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)
    org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)
    org.apache.derby.impl.sql.GenericPreparedStatement.executeStmt(Unknown Source)
    org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeLargeUpdate(Unknown Source)
    org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeUpdate(Unknown Source)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLLoggingPreparedStatement.executeUpdate(SQLLoggingPreparedStatement.java:147)
    uk.ac.bgs.GINFileUpload.Model.SQLDatabase.SQLDatabaseController.AddRecord(SQLDatabaseController.java:300)
    uk.ac.bgs.GINFileUpload.Model.Cache.addFileItem(Cache.java:213)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processUpload(CacheServlet.java:394)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.processRequest(CacheServlet.java:243)
    uk.ac.bgs.GINFileUpload.Controllers.CacheServlet.doPost(CacheServlet.java:675)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:648)
    javax.servlet.http.HttpServlet.service(HttpServlet.java:729)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:291)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52)
    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:239)
    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)
    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:217)
    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:106)
    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:614)
    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:142)
    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:79)
    org.apache.catalina.valves.AbstractAccessLogValve.invoke(AbstractAccessLogValve.java:616)
    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:88)
    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:518)
    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1091)
    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:673)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1500)
    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1456)
    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
    java.lang.Thread.run(Thread.java:745)
   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0100   994  100   994    0     0    577      0  0:00:01  0:00:01 --:--:--   577
  0 6076k    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0 23 6076k    0     0   23 1456k      0   457k  0:00:13  0:00:03  0:00:10 3200k 30 6076k    0     0   30 1872k      0   422k  0:00:14  0:00:04  0:00:10 1097k 30 6076k    0     0   30 1872k      0   344k  0:00:17  0:00:05  0:00:12  691k 30 6076k    0     0   30 1872k      0   290k  0:00:20  0:00:06  0:00:14  504k 30 6076k    0     0   30 1872k      0   251k  0:00:24  0:00:07  0:00:17  397k 30 6076k    0     0   30 1872k      0   221k  0:00:27  0:00:08  0:00:19 81031 32 6076k    0     0   32 1952k      0   204k  0:00:29  0:00:09  0:00:20 15975 32 6076k    0     0   32 1984k      0   187k  0:00:32  0:00:10  0:00:22 22365 32 6076k    0     0   32 2000k      0   176k  0:00:34  0:00:11  0:00:23 26592 33 6076k    0     0   33 2032k      0   164k  0:00:36  0:00:12  0:00:24 33226 33 6076k    0     0   33 2032k      0   152k  0:00:39  0:00:13  0:00:26 33226 34 6076k    0     0   34 2112k      0   142k  0:00:42  0:00:14  0:00:28 31189 34 6076k    0     0   34 2112k      0   133k  0:00:45  0:00:15  0:00:30 24956 34 6076k    0     0   34 2112k      0   125k  0:00:48  0:00:16  0:00:32 21035 35 6076k    0     0   35 2128k      0   122k  0:00:49  0:00:17  0:00:32 19481 36 6076k    0     0   36 2192k      0   119k  0:00:51  0:00:18  0:00:33 32469 36 6076k    0     0   36 2224k      0   110k  0:00:54  0:00:20  0:00:34 21602 36 6076k    0     0   36 2240k      0   107k  0:00:56  0:00:20  0:00:36 25595 37 6076k    0     0   37 2272k      0   103k  0:00:58  0:00:21  0:00:37 32000 37 6076k    0     0   37 2288k      0   103k  0:00:58  0:00:22  0:00:36 34218 38 6076k    0     0   38 2352k      0   101k  0:00:59  0:00:23  0:00:36 34218 39 6076k    0     0   39 2400k      0    98k  0:01:01  0:00:24  0:00:37 42455 40 6076k    0     0   40 2480k      0  99179  0:01:02  0:00:25  0:00:37 52602 41 6076k    0     0   41 2544k      0  95943  0:01:04  0:00:27  0:00:37 53388 42 6076k    0     0   42 2560k      0  93299  0:01:06  0:00:28  0:00:38 47216 42 6076k    0     0   42 2608k      0  92161  0:01:07  0:00:28  0:00:39 45385 43 6076k    0     0   43 2656k      0  90717  0:01:08  0:00:29  0:00:39 46694 43 6076k    0     0   43 2672k      0  88825  0:01:10  0:00:30  0:00:40 37823 45 6076k    0     0   45 2736k      0  88085  0:01:10  0:00:31  0:00:39 42235 45 6076k    0     0   45 2752k      0  87454  0:01:11  0:00:32  0:00:39 47639 46 6076k    0     0   46 2816k      0  86787  0:01:11  0:00:33  0:00:38 50127 46 6076k    0     0   46 2848k      0  85100  0:01:13  0:00:34  0:00:39 45829 48 6076k    0     0   48 2944k      0  83936  0:01:14  0:00:35  0:00:39 54485 48 6076k    0     0   48 2960k      0  82608  0:01:15  0:00:36  0:00:39 46945 49 6076k    0     0   49 3008k      0  81715  0:01:16  0:00:37  0:00:39 47915 50 6076k    0     0   50 3072k      0  81219  0:01:16  0:00:38  0:00:38 47619 50 6076k    0     0   50 3088k      0  79832  0:01:17  0:00:39  0:00:38 46031 51 6076k    0     0   51 3152k      0  79397  0:01:18  0:00:40  0:00:38 44972 52 6076k    0     0   52 3184k      0  77411  0:01:20  0:00:42  0:00:38 42273 52 6076k    0     0   52 3184k      0  75614  0:01:22  0:00:43  0:00:39 33221 52 6076k    0     0   52 3200k      0  74853  0:01:23  0:00:43  0:00:40 25980 53 6076k    0     0   53 3280k      0  75438  0:01:22  0:00:44  0:00:38 40009 54 6076k    0     0   54 3296k      0  74138  0:01:23  0:00:45  0:00:38 30259 54 6076k    0     0   54 3312k      0  73459  0:01:24  0:00:46  0:00:38 32355 55 6076k    0     0   55 3376k      0  73285  0:01:24  0:00:47  0:00:37 48497 56 6076k    0     0   56 3440k      0  72836  0:01:25  0:00:48  0:00:37 53577 57 6076k    0     0   57 3520k      0  71909  0:01:26  0:00:50  0:00:36 43870 57 6076k    0     0   57 3520k      0  70502  0:01:28  0:00:51  0:00:37 40952 58 6076k    0     0   58 3536k      0  70377  0:01:28  0:00:51  0:00:37 43442 60 6076k    0     0   60 3648k      0  70967  0:01:27  0:00:52  0:00:35 50965 60 6076k    0     0   60 3664k      0  70446  0:01:28  0:00:53  0:00:35 46840 61 6076k    0     0   61 3728k      0  70461  0:01:28  0:00:54  0:00:34 52551 63 6076k    0     0   63 3840k      0  70959  0:01:27  0:00:55  0:00:32 76400 65 6076k    0     0   65 3968k      0  71598  0:01:26  0:00:56  0:00:30 83449 66 6076k    0     0   66 4048k      0  72205  0:01:26  0:00:57  0:00:29 85852 67 6076k    0     0   67 4080k      0  71796  0:01:26  0:00:58  0:00:28 86371 69 6076k    0     0   69 4240k      0  73160  0:01:25  0:00:59  0:00:26   99k 71 6076k    0     0   71 4352k      0  73248  0:01:24  0:01:00  0:00:24 96642 72 6076k    0     0   72 4400k      0  73166  0:01:25  0:01:01  0:00:24 91587 74 6076k    0     0   74 4512k      0  73476  0:01:24  0:01:02  0:00:22 86814 74 6076k    0     0   74 4528k      0  73041  0:01:25  0:01:03  0:00:22 86737 77 6076k    0     0   77 4736k      0  75527  0:01:22  0:01:04  0:00:18  101k 81 6076k    0     0   81 4928k      0  76311  0:01:21  0:01:06  0:00:15  108k 81 6076k    0     0   81 4944k      0  75849  0:01:22  0:01:06  0:00:16  105k 83 6076k    0     0   83 5088k      0  77239  0:01:20  0:01:07  0:00:13  125k 86 6076k    0     0   86 5280k      0  78949  0:01:18  0:01:08  0:00:10  150k 88 6076k    0     0   88 5376k      0  78854  0:01:18  0:01:09  0:00:09  114k 89 6076k    0     0   89 5440k      0  79292  0:01:18  0:01:10  0:00:08  124k 91 6076k    0     0   91 5568k      0  79694  0:01:18  0:01:11  0:00:07  130k 93 6076k    0     0   93 5664k      0  79349  0:01:18  0:01:13  0:00:05  102k 93 6076k    0     0   93 5680k      0  78925  0:01:18  0:01:13  0:00:05 78602 94 6076k    0     0   94 5760k      0  79383  0:01:18  0:01:14  0:00:04 87595 97 6076k    0     0   97 5952k      0  80966  0:01:16  0:01:15  0:00:01  101k100 6076k    0     0  100 6076k      0  81571  0:01:16  0:01:16 --:--:--  107k100 6076k    0     0  100 6076k      0  80514  0:01:17  0:01:17 --:--:--   98k100 6076k    0     0  100 6076k      0  79484  0:01:18  0:01:18 --:--:-- 88451100 6076k    0     0  100 6076k      0  78481  0:01:19  0:01:19 --:--:-- 65045100 6076k    0     0  100 6076k      0  77503  0:01:20  0:01:20 --:--:-- 25477100 6076k    0     0  100 6076k      0  76548  0:01:21  0:01:21 --:--:--     0100 6076k    0     0  100 6076k      0  75617  0:01:22  0:01:22 --:--:--     0100 6076k    0     0  100 6076k      0  74708  0:01:23  0:01:23 --:--:--     0100 6076k    0     0  100 6076k      0  73821  0:01:24  0:01:24 --:--:--     0100 6076k    0     0  100 6076k      0  72955  0:01:25  0:01:25 --:--:--     0100 6076k    0     0  100 6076k      0  72108  0:01:26  0:01:26 --:--:--     0100 6076k    0     0  100 6076k      0  71282  0:01:27  0:01:27 --:--:--     0100 6076k    0     0  100 6076k      0  70474  0:01:28  0:01:28 --:--:--     0100 6076k    0     0  100 6076k      0  69684  0:01:29  0:01:29 --:--:--     0100 6076k    0     0  100 6076k      0  68911  0:01:30  0:01:30 --:--:--     0100 6076k    0     0  100 6076k      0  68155  0:01:31  0:01:31 --:--:--     0100 6076k    0     0  100 6076k      0  67416  0:01:32  0:01:32 --:--:--     0100 6076k    0     0  100 6076k      0  66692  0:01:33  0:01:33 --:--:--     0100 6086k    0 10276  100 6076k    109  66467  0:01:33  0:01:33 --:--:--     0

False
  -- Uploading minute data to GIN: 20200527
No faillog existing
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
Success
Data loaded OK, data file id = 33813349
   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0   994    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0100   994  100   994    0     0    960      0  0:00:01  0:00:01 --:--:--   961
  0  103k    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0100  103k    0     0  100  103k      0  34731  0:00:03  0:00:03 --:--:-- 75049100  103k    0     0  100  103k      0  28437  0:00:03  0:00:03 --:--:-- 50779100  103k  100    48  100  103k     12  28435  0:00:04  0:00:03  0:00:01 50779

True
----------------------------------------------------------------
Part 3: determine quasidefinite data
----------------------------------------------------------------
  - Current weekday: 4
 a) Checking whether current time is suitable for QD
    - QD calculation will be performed on day 5 between 3:00 and 4:00
  - Not time for Quasidefinitve data determinations - waiting for 2:00 am
-----------------------------------
Part3 needs 0:00:00.000036
-----------------------------------
----------------------------------------------------------------
Part 5: create plots and upload them to webpage
----------------------------------------------------------------
('Part5 - Creating plot:', u'LEMI036_1_0002_0002', u'GP20S3NSS2_012201_0001_0001')
 - Saving diagram to products folder
 - kvalues
-------------------------
Dealing with key: x
-------------------------
Dealing with key: y
-------------------------
Dealing with key: z
ndtype - Timeseries ending at: 2020-05-29 14:30:00+00:00
Coverage in days: 2.60416666663
Last effective time series ending at day 2020-05-29 00:00:00
 -----------------------------------------------------
 ------------- Starting backward analysis ------------
 --------------- beginning at last time --------------
Step0 needed: 0:00:00.000128
Step1 needed: 0:00:00.003237
Step2 needed: 0:00:00.948909
Step3 needed: 0:00:00.005563
Step4 needed: 0:00:01.009731
Step5 needed: 0:00:00.015446
 -----------------------------------------------------
 ------------- Starting forward analysis -------------
 -----------------  from first date ------------------
Running daily chunks forward until  2020-05-28 00:00:00+00:00
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 02:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 01:30:00+00:00
as the extended time range is not reached
----------------------------------------------
##############################################
 careful - datastream not long enough for correct k determination
##############################################
Hourly means not correctly determinable for day 2020-05-27 00:30:00+00:00
as the extended time range is not reached
----------------------------------------------
Running daily chunks forward until  2020-05-29 00:00:00+00:00
Checking kvals
Index: 0, time: 2020-05-27 22:30:00+00:00, kval: 0.0
Index: 1, time: 2020-05-28 01:30:00+00:00, kval: 1.0
Index: 2, time: 2020-05-28 04:30:00+00:00, kval: 1.0
Index: 3, time: 2020-05-28 07:30:00+00:00, kval: 0.0
Index: 4, time: 2020-05-28 10:30:00+00:00, kval: 1.0
Index: 5, time: 20/home/cobs/anaconda2/lib/python2.7/site-packages/magpy/database.py:1974: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if not col[0] or col[0] in ['nan', '-','']: #remove place holders
20-05-28 13:30:00+00:00, kval: 1.0
Index: 6, time: 2020-05-28 16:30:00+00:00, kval: 1.0
Index: 7, time: 2020-05-28 19:30:00+00:00, kval: 0.0
Index: 8, time: 2020-05-28 22:30:00+00:00, kval: 1.0
Index: 9, time: 2020-05-29 01:30:00+00:00, kval: 1.0
Index: 10, time: 2020-05-29 04:30:00+00:00, kval: 1.0
Index: 11, time: 2020-05-29 07:30:00+00:00, kval: 1.0
Index: 12, time: 2020-05-29 10:30:00+00:00, kval: 1.0
Index: 13, time: 2020-05-29 13:30:00+00:00, kval: 1.0
13
None
Expect k of 1.0 until 2020-05-29 13:30 + 1.5 hours UTC (current time = 2020-05-29 14:35:25.835066)
K value has been updated to 1.0
  -> Now writing kvals to database
  -> Done
  -> Now writing kvals to secondary database
  -> Done
 -- Starting scptransfer with timeout 300
*resp* '226 Transfer complete'
*cmd* 'QUIT'
*resp* '221 Goodbye.'
 
magvar_2020-05-29.png                           0%    0     0.0KB/s   --:-- ETAmagvar_2020-05-29.png                         100%  109KB 108.6KB/s   00:00    

 -- now removing temporary file...
  - Uploading of plots successful
-----------------------------------
All Parts needed: 0:04:16.005361
-----------------------------------
{'SAGITTARIUS-DataProducts-magnetism-step5a': 'creating and saving graph successful', 'SAGITTARIUS-DataProducts-magnetism-step5b': 'determinig k successfull', 'SAGITTARIUS-DataProducts-magnetism-step3b': 'last quasidefinitive calculation successful', 'SAGITTARIUS-DataProducts-magnetism-step3c': 'qd coverage ok', 'SAGITTARIUS-DataProducts-magnetism-step3a': 'last suitability test for quasidefinitive finished', 'SAGITTARIUS-DataProducts-magnetism-step4': 'last upload of QD successful', 'SAGITTARIUS-DataProducts-magnetism-step5': 'uploading plots successful', 'SAGITTARIUS-DataProducts-magnetism-step2': 'upload successful', 'SAGITTARIUS-DataProducts-magnetism-obligatory directories': 'all accessible', 'SAGITTARIUS-DataProducts-magnetism-step1d': 'baseline correction successful', 'SAGITTARIUS-DataProducts-magnetism-step1e': 'all data files saved', 'SAGITTARIUS-DataProducts-magnetism-step1a': 'primary instruments selected', 'SAGITTARIUS-DataProducts-magnetism-step1b': 'variometer data loaded', 'SAGITTARIUS-DataProducts-magnetism-step1c': 'scalar data loaded'}
Logfile /var/log/magpy/mm-dp-magnetism.log loaded
Existing: SAGITTARIUS-DataProducts-magnetism-step5a
Existing: SAGITTARIUS-DataProducts-magnetism-step5b
Existing: SAGITTARIUS-DataProducts-magnetism-step3b
Existing: SAGITTARIUS-DataProducts-magnetism-step3c
Existing: SAGITTARIUS-DataProducts-magnetism-step3a
Existing: SAGITTARIUS-DataProducts-magnetism-step4
Existing: SAGITTARIUS-DataProducts-magnetism-step5
Existing: SAGITTARIUS-DataProducts-magnetism-step2
Existing: SAGITTARIUS-DataProducts-magnetism-obligatory directories
Existing: SAGITTARIUS-DataProducts-magnetism-step1d
Existing: SAGITTARIUS-DataProducts-magnetism-step1e
Existing: SAGITTARIUS-DataProducts-magnetism-step1a
Existing: SAGITTARIUS-DataProducts-magnetism-step1b
Existing: SAGITTARIUS-DataProducts-magnetism-step1c
Fri May 29 14:35:31 UTC 2020
4. Activity information 
/home/cobs/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')
Getuser: Running from crontab -- trying Logname to identify user
Getuser: ... succes - using cobs
Accessing credential file: /home/cobs/.magpycred
Connecting to primary MARCOS...
success
Reading k values from database
readDB: Read rows: 4
readDB: Found identical values only:var1
readDB: Found identical values only:var3
[array([ 737574.1875,  737574.3125,  737574.4375,  737574.5625])
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([ 1.,  1.,  1.,  1.])
 array([ 5.42832766,  6.89895013,  5.9039304 ,  6.47414742])
 array([ 1.,  1.,  1.,  1.]) array([], dtype=float64)
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([], dtype=float64) array([], dtype=float64) array([], dtype=float64)
 array([], dtype=float64)]
Current k-value: 1.0
Valid until: 2020-05-29 15:00:00
Updating json
K warning data has been updated
Successfully finished
Fri May 29 14:35:34 UTC 2020
